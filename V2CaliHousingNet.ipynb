{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "def load_housing_data():\n",
    "    tarball_path = Path(\"datasets/housing.tgz\")\n",
    "    if not tarball_path.is_file():\n",
    "        Path(\"datasets\").mkdir(parents=True ,exist_ok=True)\n",
    "        url = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.tgz\"\n",
    "        urllib.request.urlretrieve(url, tarball_path)\n",
    "        with tarfile.open(tarball_path) as housing_tarball:\n",
    "            housing_tarball.extractall(path=\"datasets\")\n",
    "    return pd.read_csv(Path(\"datasets/housing.csv\"))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path(\"datasets/housing.csv\")\n",
    "dataset_line = tf.data.TextLineDataset(str(dataset_path))\n",
    "record_defaults = [tf.constant([0.], dtype=tf.float32)] * 7 + [tf.constant([0.], dtype=tf.float32)] * 2 + [tf.constant([], dtype=tf.string)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parserx(line):\n",
    "    x = tf.io.decode_csv(line, record_defaults=record_defaults)\n",
    "    features1 = tf.stack(x[:8])\n",
    "    features2 = tf.stack(tf.concat([x[0:2], x[3:5]], axis=0))\n",
    "    return features1 , features2\n",
    "def parsery(line):\n",
    "    x = tf.io.decode_csv(line, record_defaults=record_defaults)\n",
    "    return tf.stack(x[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = dataset_line.skip(1).map(parserx)\n",
    "data_y = dataset_line.skip(1).map(parsery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x_wide_array = tf.TensorArray(tf.float32, size = 0 , dynamic_size=True)\n",
    "data_x_deep_array = tf.TensorArray(tf.float32, size = 0 , dynamic_size=True)\n",
    "data_y_array = tf.TensorArray(tf.float32, size = 0, dynamic_size = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in data_x:\n",
    "    data_x_deep_array = data_x_deep_array.write(data_x_deep_array.size(), x)\n",
    "    data_x_wide_array = data_x_wide_array.write(data_x_wide_array.size(), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_deep = data_x_deep_array.stack()\n",
    "train_x_wide = data_x_wide_array.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in data_y:\n",
    "    data_y_array = data_y_array.write(data_y_array.size(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = data_y_array.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([452600., 358500., 352100., 341300.], dtype=float32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianRegNoiseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, stddev,activation=None, **kwargs):\n",
    "        super().__init__(*(kwargs))\n",
    "        self.stddev = stddev\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight('kernel', shape = [batch_input_shape[-1],self.units ],\n",
    "                                      initializer='glorot_normal')\n",
    "        self.bias = self.add_weight('bias', shape = [self.units],\n",
    "                                    initializer='zeros')\n",
    "\n",
    "    def call(self, X,training = False):\n",
    "        shape = tf.shape(X)\n",
    "        noise = tf.random.normal([shape[0], self.units], stddev=self.stddev)\n",
    "        if self.activation is not None:\n",
    "            if training:\n",
    "                return self.activation(tf.matmul(X, self.kernel) + self.bias) + noise\n",
    "            else:\n",
    "                return self.activation(tf.matmul(X, self.kernel) + self.bias)\n",
    "        if self.activation is None:\n",
    "            if training:\n",
    "                return tf.matmul(X, self.kernel) + self.bias + noise\n",
    "            else:\n",
    "                return tf.matmul(X, self.kernel) + self.bias\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        base_config.update({'stddev':self.stddev,\n",
    "                            'units':self.units, \n",
    "                            'activation':tf.keras.activations.serialize(self.activation)})\n",
    "        return base_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualIOGaussianRT(tf.keras.Model):\n",
    "    def __init__(self, architecture, keen_units, layer_depth, g_units , **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.architecture = architecture\n",
    "        self.keen_units = keen_units\n",
    "        self.g_units = g_units\n",
    "        self.layer_depth = layer_depth\n",
    "        self.deep_norm_ = tf.keras.layers.Normalization()\n",
    "        self.wide_norm_ = tf.keras.layers.Normalization()\n",
    "        self.DeepFlow_ = [tf.keras.layers.Dense(units, activation = 'relu',\n",
    "                                                kernel_initializer = tf.keras.initializers.glorot_normal(),\n",
    "                                                kernel_regularizer = tf.keras.regularizers.l2(0.01),\n",
    "                                                bias_regularizer= tf.keras.regularizers.L2(0.01)) for units in architecture]\n",
    "        self.BatchNormDeep_ = [tf.keras.layers.BatchNormalization() for _ in architecture]\n",
    "        self.WideFlow = [tf.keras.layers.Dense(keen_units,\n",
    "                                               activation = tf.keras.layers.LeakyReLU(),\n",
    "                                               kernel_initializer = tf.keras.layers.he_normal(),\n",
    "                                               kernel_regularizer= tf.keras.regularizers.L2(0.1)) for _ in range(self.layer_depth)]\n",
    "        self.BatchNormWide_ = tf.keras.layers.BatchNormalization()\n",
    "        self.GRNlayer  = GaussianRegNoiseLayer(g_units, 0.1, activation = 'relu')\n",
    "        self.concatenate_ = tf.keras.layers.Concatenate()\n",
    "        self.output_1 = tf.keras.layers.Dense(1, activation = tf.keras.activations.linear(),\n",
    "                                              kernel_initializer = tf.keras.initializers.glorot_normal())\n",
    "        self.output_2 = tf.keras.layers.Dense(1, activation = tf.keras.activations.linear(),\n",
    "                                              kernel_initializer = tf.keras.initializers.glorot_normal())\n",
    "        \n",
    "        def call(self, input):\n",
    "            x_deep , x_wide = input\n",
    "            x_deep = self.deep_norm_(x_deep)\n",
    "            x_wide = self.wide_norm_(x_wide)\n",
    "            for layer, norm in zip(self.DeepFlow_, self.BatchNormDeep_):\n",
    "                x_deep = layer(x_deep)\n",
    "                x_deep = norm(x_deep)\n",
    "            for l in self.WideFlow:\n",
    "                x_wide = l(x_wide)\n",
    "            x_wide = self.BatchNormWide_(x_wide)\n",
    "            x_wide = self.GRNlayer(x_wide)\n",
    "            x = self.concatenate_([x_deep, x_wide])\n",
    "            output_1 = self.output_1(x)\n",
    "            output_2 = self.output_2(x_deep)\n",
    "\n",
    "        def get_config(self):\n",
    "            base_config = super().get_config()\n",
    "            base_config.update({'architecture':self.architecture,\n",
    "                                'keen_units':self.keen_units,\n",
    "                                'g_units':self.g_units,\n",
    "                                'layer_depth':self.layer_depth})\n",
    "            return base_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
